{"cells":[{"cell_type":"markdown","source":["## Ã‡anakkale Onsekiz Mart Ãœniversitesi MÃ¼hendislik FakÃ¼ltesi, Bilgisayar MÃ¼hendisliÄŸi\n","\n","## 2022-2023 Akademik YÄ±lÄ± - Bahar DÃ¶nemi\n","\n","## **BLM-4014 Yapay Sinir AÄŸlarÄ± FÄ°NAL SINAVI SORU VE CEVAP KAÄIDI**\n","\n","### Ã–ÄŸretim ElemanÄ±: Dr. Ã–ÄŸretim Ãœyesi Ulya Bayram\n","\n","**SÄ±nav sÃ¼resi: en fazla 3 saat**\n"],"metadata":{"id":"l-DSiPiOoPim"}},{"cell_type":"markdown","source":["AÃ§Ä±klamalar:\n","\n","* Ä°lk olarak, bu notebook'u File kÄ±smÄ±ndan \"**Save a copy in Gdrive**\" seÃ§eneÄŸine basarak kendi Google Colab'Ä±nÄ±za kopyalayÄ±p onun Ã¼zerinde Ã§Ã¶zmeye baÅŸlayÄ±n.\n","* **LÃ¼tfen sorularÄ± dikkatli okuyun!**\n","* Ä°nternet, ChatGPT, Bard gibi olanaklarÄ± kullanmak **serbest**!\n","* Birbirinizden/insanlardan yardÄ±m almak YASAK! UnutmayÄ±n ki size yardÄ±m eden arkadaÅŸÄ±nÄ±z soruyu yanlÄ±ÅŸ Ã§Ã¶zÃ¼nce siz de dÃ¼ÅŸÃ¼k not alÄ±yorsunuz. Oysa kendi baÅŸÄ±nÄ±za, serbest bÄ±raktÄ±ÄŸÄ±m AI yÃ¶ntemlerini kullanarak doÄŸru Ã§Ã¶zÃ¼me kendiniz ulaÅŸabilirsiniz! Hatalar ve dÃ¼ÅŸÃ¼k not da baÅŸkasÄ±nÄ±n yÃ¼zÃ¼nden olmaz! UnutmayÄ±n ki iÅŸe girdiÄŸinizde kimse sizin yerinize kod yazmayacak, kendi baÅŸÄ±nÄ±zasÄ±nÄ±z ğŸ˜‰\n","* Sorular sizden kodlarÄ± aÃ§Ä±klamanÄ±zÄ± istiyorsa, eklenmiÅŸ text cell'ine lÃ¼tfen elinizden geldiÄŸince kodu yazarken bildiklerinizi/dÃ¼ÅŸÃ¼ndÃ¼klerinizi aÃ§Ä±klayarak yazÄ±n. Tek cÃ¼mlelik, aÃ§Ä±klayÄ±cÄ± olmayan - yetersiz aÃ§Ä±klamalar puan alamaz.\n","* Tek bir cell'e istenen kodlarÄ± yazmak zorunda deÄŸilsiniz. Yeni cell'ler aÃ§abilirsiniz.\n","* LÃ¼tfen derste gÃ¶rdÃ¼ÄŸÃ¼nÃ¼z gibi pytorch kullanÄ±n. Derste gÃ¶rmediÄŸimiz iÃ§in Tensorflow kodlarÄ±na puan veremem.\n","* Derste gÃ¶rmediÄŸimiz hiÃ§bir iÃ§erik yok bu sÄ±navda, lÃ¼tfen Ã¶zgÃ¼venli baÅŸlayÄ±n Ã§Ã¶zmeye.\n","* AynÄ± sÃ¼rede yorgun kafayla Ã§Ã¶zmeyi denedim, sadece CPU kullandÄ±m, bilerek vakit kaybettim ve kodlarÄ± bÃ¼yÃ¼k bir veri setinde Ã§alÄ±ÅŸtÄ±rmama raÄŸmen bir saatte bitti. En fazla 2 saat gayet yeter ve artar - yine de 3 saat verebilirim. 3 saatten daha da fazla olamaz o yÃ¼zden sÃ¼re ile ilgili itiraz kabul etmiyorum. GerÃ§ek hayatta Ã§ok daha kÄ±sa sÃ¼rede Ã§ok daha zorlarÄ±nÄ± yazmanÄ±z beklenecek!\n","* Ã‡Ã¶zÃ¼mÃ¼nÃ¼zÃ¼ pdf olarak kaydedip (google colab'da File>print kÄ±smÄ±na basÄ±p \"Save as PDF\" seÃ§eneÄŸi ya da hangi ortamÄ± kullanacaksanÄ±z orada okunabilir haliyle pdf olarak kaydedin) final gÃ¼nÃ¼ aÃ§acaÄŸÄ±m Teams assignment kÄ±smÄ±na belirttiÄŸim saat sÃ¼resinde yÃ¼kleyin. GeÃ§ upload'larÄ± kabul etmiyorum. PDF olmayan upload'larÄ± kabul etmiyorum!\n","* Notebook'u github'a yÃ¼klemeyin Ã§Ã¼nkÃ¼ bazÄ± kodlar error iÃ§ereceÄŸi iÃ§in github'daki projelerinizin yanÄ±nda durmasÄ±n sizi kÃ¶tÃ¼ gÃ¶sterebilir.\n","* **BAÅARILAR!**\n","\n"],"metadata":{"id":"AWnWthLLo2vf"}},{"cell_type":"markdown","source":["Bu sÄ±navda iki farklÄ± yapay sinir aÄŸÄ± problemi Ã¼zerinde Ã§alÄ±ÅŸacaksÄ±nÄ±z."],"metadata":{"id":"dWHNXfFBqseT"}},{"cell_type":"markdown","source":["## Ã–ÄŸrencinin AdÄ± SoyadÄ±: Demircan Ã–zdemir\n","\n","## Ã–ÄŸrenci No: 190401016"],"metadata":{"id":"OT2yxbSzuV_z"}},{"cell_type":"code","source":["# Ã–ÄŸrenci numaranÄ±zÄ± bir global variable olarak bu cell'de tanÄ±mlayÄ±n ve\n","# cell'i Ã§alÄ±ÅŸtÄ±rÄ±n! \n","# AÅŸaÄŸÄ±daki kodlarda kullanmanÄ±z istenecek.\n","\n","STUDENT_NO = \"190401016\""],"metadata":{"id":"EpS4zhW0uhwb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SORU - 1: Toplam 50 Puan\n","\n","Ã‡alÄ±ÅŸtÄ±ÄŸÄ±nÄ±z self-driving otomobil ÅŸirketi, otomobillerin yolda gÃ¶rdÃ¼ÄŸÃ¼ Ã§eÅŸitli objelere Ã§arptÄ±ÄŸÄ±nÄ± tespit ediyor ve aracÄ±n basÄ±n Ã¶nÃ¼nde demo gÃ¶sterimine saatler kala, hÄ±zlÄ±ca sizden \"UÃ§ak, Otomobil, KuÅŸ, Kedi, Geyik, KÃ¶pek, KurbaÄŸa, At, Gemi ve TÄ±r\" objelerini doÄŸru tespit ederek birbirinden ayÄ±rÄ±p doÄŸru sÄ±nÄ±flandÄ±rabilen bir yapay sinir aÄŸÄ± algoritmasÄ± oluÅŸturup, kodunu kÄ±sa sÃ¼rede yazmanÄ±zÄ± istiyor. Åirketin geleceÄŸi sizin elinizde!\n","\n","torchvision.datasets iÃ§indeki CIFAR10 verisetini kullanmanÄ±z gerekiyor.\n","\n","KodlarÄ±n Ã§alÄ±ÅŸmasÄ±nÄ± hÄ±zlandÄ±rmak iÃ§in gerekli kÄ±sÄ±mlarda GPU ya da TPU kullanmanÄ±z serbest ama zorunlu deÄŸil."],"metadata":{"id":"Sw1EARzZq71r"}},{"cell_type":"markdown","source":["1.1) (5 Puan) Veri setini aÅŸaÄŸÄ±daki cell'de Ã§aÄŸÄ±rÄ±n, training, validation ve test setlerine ayÄ±rÄ±n. Veri sayÄ±sÄ± Ã§ok fazla olduÄŸu iÃ§in training/validation/test setlerini istediÄŸiniz kadar ufaltabilirsiniz. Ama hiÃ§bir set 1000 sample'dan az olmasÄ±n! (Alt limit herhangi bir set iÃ§in 1000 yani)\n","\n","Dersteki gibi bu setleri batch'lere ayÄ±rmanÄ±z gerekiyor gerekli yÃ¶ntemleri kullanarak.\n","\n","batch_size = 32"],"metadata":{"id":"8udQfalJt13S"}},{"cell_type":"code","source":["# Veri iÅŸleme kÄ±sÄ±mlarÄ±\n","#Batch size\n","batchsize = 32\n","\n","import torch\n","import torchvision\n","\n","# Download the CIFAR10 dataset\n","# If the dataset is already downloaded, this step will be skipped\n","torchvision.datasets.CIFAR10(root='./data', download=True)\n","\n","# Create a dataset object for the training set\n","train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=torchvision.transforms.ToTensor())\n","\n","# Get the total number of samples in the training set\n","num_train_samples = len(train_dataset)\n","\n","# Split the dataset into train, test, and validation sets\n","train_size = int(0.7 * num_train_samples)\n","val_size = int(0.15 * num_train_samples)\n","test_size = num_train_samples - train_size - val_size\n","\n","train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n","    train_dataset, [train_size, val_size, test_size]\n",")\n","\n","# Create data loaders for the train, test, and validation sets\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=batchsize, shuffle=True\n",")\n","val_loader = torch.utils.data.DataLoader(\n","    val_dataset, batch_size=batchsize, shuffle=False\n",")\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=batchsize, shuffle=False\n",")\n","\n","print(train_loader, test_loader,val_loader)"],"metadata":{"id":"iDjisBcDuRR_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686141559577,"user_tz":-180,"elapsed":17728,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}},"outputId":"cab8fc99-c9a5-455b-8d2a-c6440945152d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170498071/170498071 [00:03<00:00, 48774310.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","<torch.utils.data.dataloader.DataLoader object at 0x7f5a09743d90> <torch.utils.data.dataloader.DataLoader object at 0x7f5adc8677c0> <torch.utils.data.dataloader.DataLoader object at 0x7f5aa8571060>\n"]}]},{"cell_type":"markdown","source":["1.2) (5 Puan) Yapay sinir aÄŸÄ±nÄ±n class'Ä±nÄ± aÅŸaÄŸÄ± yazÄ±n. \n","\n","*   Tek hidden layer kullanÄ±n. \n","*   Hidden layer'da nÃ¶ron sayÄ±sÄ± olarak Ã¶ÄŸrenci numaranÄ±zÄ±n son 4 rakamÄ±nÄ± kullanÄ±n. STUDENT_NO global variable'Ä±ndan bu son 4 rakamÄ± Ã§Ä±karacak kodu yazmanÄ±z lazÄ±m, elle yazarsanÄ±z -2 puan!\n","* RegÃ¼larizasyon yÃ¶ntemleri eklemeyin ÅŸimdilik.\n","\n","Aktivasyon yÃ¶ntemlerini siz seÃ§eceksiniz.\n","\n"],"metadata":{"id":"zWN4XatRvB4t"}},{"cell_type":"code","source":["# class kÄ±smÄ±\n","# import torch #daha Ã¶nceden import edili\n","from torch.nn import Module, Linear, Sigmoid\n","\n","class NeuralNetwork(Module):\n","    def __init__(self, hidden_layer_neurons = int(STUDENT_NO[-4:]) ):\n","        super().__init__()\n","        # The input layer has 32 neurons\n","        self.input_layer = Linear(32*32*3, hidden_layer_neurons)\n","        # The hidden layer has the specified number of neurons\n","        self.hidden_layer = Linear(hidden_layer_neurons, 10)\n","        # The output layer has 10 neurons, one for each class\n","        self.output_layer = Linear(10, 10)\n","        # The activation function for the hidden layer is a sigmoid function\n","        self.activation_function = Sigmoid()\n","\n","    def forward(self, x):\n","        # The input layer is passed through the hidden layer\n","        x = self.activation_function(self.input_layer(x))\n","        # The hidden layer is passed through the output layer\n","        x = self.output_layer(x)\n","        # The output layer is returned\n","        return x\n"],"metadata":{"id":"ki2C2Tlpy31w","executionInfo":{"status":"ok","timestamp":1686146521404,"user_tz":-180,"elapsed":236,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}}},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":["1.3) (Toplam 10 Puan) Bu yapay sinir aÄŸÄ±nÄ± train ve validate edecek kodlarÄ± aÅŸaÄŸÄ± yazÄ±n. Training ve validation loss'u plot edin. Earlystopping kullanÄ±n ki overfit etmesin!\n","\n","\n","\n","*   Epoch sayÄ±sÄ± seÃ§imi size kalmÄ±ÅŸ. Underfit de etmesin!\n","*   Learning rate seÃ§imi size kalmÄ±ÅŸ. FarklÄ± ÅŸeyleri deneyebilirsiniz.\n","* Optimizasyon seÃ§imi size kalmÄ±ÅŸ. \n","* Earlystop dÄ±ÅŸÄ±nda regÃ¼larizasyon istemiyoruz!  Patience 2 olabilir.\n","\n","\n","\n"],"metadata":{"id":"uuBSljkQzoI7"}},{"cell_type":"code","source":["# training ve validation kÄ±smÄ±\n","# import torch\n","# import torchvision\n","# from torch.nn import Module, Linear, Sigmoid\n","from torch.optim import SGD\n","\n","def train(model, train_loader, optimizer, criterion, epochs):\n","    for epoch in range(epochs):\n","        model.train()\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","            optimizer.step()\n","\n","def validate(model, val_loader, criterion):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in val_loader:\n","            data, target = data, target.view(-1, 16)\n","            output = model(data)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target).sum().item()\n","            total += len(target)\n","    return correct / total\n","\n","best_val_loss = None\n","patience = 2\n","\n","if __name__ == \"__main__\":\n","    \n","    # Create the neural network\n","    model = NeuralNetwork(16)\n","\n","    # Choose the optimizer and the loss function\n","    optimizer = SGD(model.parameters(), lr=0.01)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    # Train the model\n","    epochs = 10\n","    for epoch in range(epochs):\n","        train(model, train_loader, optimizer, criterion, epochs = epochs)\n","        val_accuracy = validate(model, val_loader, criterion)\n","        if val_accuracy < 0.99:\n","            break\n","\n","    # Test the model\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            output = model(data)\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target).sum().item()\n","            total += len(target)\n","\n","    test_accuracy = correct / total\n","    print(\"Test accuracy:\", test_accuracy)\n","\n","\n"],"metadata":{"id":"lxI_t1XP0bkJ","executionInfo":{"status":"ok","timestamp":1686143756183,"user_tz":-180,"elapsed":253,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import numpy as np\n","import pandas as pd\n","\n","\n","# Model oluÅŸturumu\n","model = NeuralNetwork()\n","\n","# Create the optimizer\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","# Create the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Load the data\n","train_data = train_loader\n","val_data = val_loader\n","test_data = test_loader\n","\n","# Train the model\n","epochs = 10\n","\n","for epoch in range(epochs):\n","    model.train()\n","    for i,data in enumerate(train_data):\n","      inputs,labels = data\n","      # inputs.reshape(32,32*32*3)\n","      optimizer.zero_grad()\n","\n","      outputs = model(inputs) ### ------> HATA <------\n","\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","      # training_count += 1\n","      # training_loss += loss.item()\n","\n","# Validate the model\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data, target in val_data:\n","            output = model(data)\n","            _, pred = output.max(1)\n","            correct += pred.eq(target).sum().item()\n","            total += len(target)\n","        val_accuracy = correct / total\n","\n","# Test the model\n","model.eval()\n","correct = 0\n","total = 0\n","with torch.no_grad():\n","    for data, target in test_data:\n","        output = model(data)\n","        _, pred = output.max(1)\n","        correct += pred.eq(target).sum().item()\n","        total += len(target)\n","    test_accuracy = correct / total\n","\n","print(\"Train accuracy:\", val_accuracy)\n","print(\"Test accuracy:\", test_accuracy)\n"],"metadata":{"id":"dVxXp02k28YD","colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"status":"error","timestamp":1686146528142,"user_tz":-180,"elapsed":226,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}},"outputId":"cb980f40-ad7b-4153-80b0-8f24e21d55ce"},"execution_count":29,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-6c33217c3776>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m### ------> HATA <------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-28-8d29da25ced4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# The input layer is passed through the hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# The hidden layer is passed through the output layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3072x32 and 3072x1016)"]}]},{"cell_type":"markdown","source":["# Burada;\n","    outputs = model(inputs)\n","  satÄ±rÄ±nda hata aldÄ±m ( iki yolda da ) . AldÄ±ÄŸÄ±m hatanÄ±n sebebi matris boyutlarÄ±nÄ±n birbirine uymamasÄ±. AldÄ±ÄŸÄ±m hata:\n","  \n","\n","```\n","RuntimeError: mat1 and mat2 shapes cannot be multiplied (3072x1016 and 10x10)\n","```\n","'Bard'tan aldÄ±ÄŸÄ±m yardÄ±mda hatanÄ±n\n"," \n","    inputs.reshape(32,32\\*32\\*3) \n","\n","  kodu ile bu sorunun ortadan kalkacaÄŸÄ±nÄ± sÃ¶yledi fakat reshape sÄ±kÄ±ntÄ±yÄ± gidermedi. chati devam ettirdiÄŸimde sorunun hidden layerdaki nÃ¶ron sayÄ±sÄ± olduÄŸunu anladÄ±m (19040>1016<). \n","  ## Bu hatayÄ± Ã§Ã¶zemediÄŸimden aÅŸaÄŸÄ±da kodun Ã§alÄ±ÅŸabileceÄŸi bir nÃ¶ran sayÄ±sÄ± ile devam edeceÄŸim.\n","  ## farklÄ± bir deÄŸer ile de Ã§Ã¶zemedim "],"metadata":{"id":"_EvhgVYdF_iP"}},{"cell_type":"markdown","source":["1.4) (Toplam 10 Puan) YukarÄ±da eÄŸitim sonunda en iyi validation sonucunu veren modeli test seti Ã¼zerinde deneyip precision, recall, F1 sonuÃ§larÄ±nÄ± (sklearn serbest) print edin."],"metadata":{"id":"pd-RBwbP2Lgt"}},{"cell_type":"code","source":["# test set performansÄ±\n","\n"],"metadata":{"id":"Iz03U3382az5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1.5) (Toplam 20 Puan) 1.3 ve 1.4'teki kodlarÄ± aÅŸaÄŸÄ± yapÄ±ÅŸtÄ±rÄ±n ve ÅŸu deÄŸiÅŸiklikleri yapÄ±p aynÄ± ÅŸekilde train/validation plot'unu ve test performansÄ±nÄ± alÄ±n. BaÅŸka hiÃ§bir parametreyi deÄŸiÅŸtirmeyin, yani seÃ§tiÄŸiniz epoch sayÄ±sÄ± ve learning rate vs. sayÄ±larÄ± aynÄ± kalsÄ±n.\n","\n","\n","\n","*   Ekstra bir regÃ¼larizasyon yÃ¶ntemi ekleyin.\n","*   1.3'tekinden farklÄ± bir optimizasyon yÃ¶ntemi deneyin.\n","* AldÄ±ÄŸÄ±nÄ±z yeni sonuÃ§larla 1.3 ve 1.4'teki sonuÃ§lar arasÄ±nda farklÄ±lÄ±klar varsa bunlarÄ± ve sizce sebeplerini aÃ§Ä±klayÄ±n.\n","\n"],"metadata":{"id":"i6BJI4hX2iDc"}},{"cell_type":"code","source":["# \n","\n","\n"],"metadata":{"id":"rp5Vpblw2xjm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# \n","\n","\n"],"metadata":{"id":"0Yuo8Dls2y6E"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["(Varsa) farklÄ±lÄ±klar ve sebepleri:\n","\n","\n",".....\n","\n","\n"],"metadata":{"id":"DQyk4bo_3int"}},{"cell_type":"markdown","source":["# SORU - 2: Toplam 50 Puan\n","\n","CEO'su olduÄŸunuz start-up yazÄ±lÄ±m ÅŸirketinde yaz stajÄ±nÄ± yapan Ã¶ÄŸrenci, ona verdiÄŸiniz kodlama gÃ¶revini stajÄ±n son gÃ¼nÃ¼ne kadar vermedi ve son gÃ¼n, staj bitimi raporunu size aceleyle imzalatÄ±p sizle vedalaÅŸtÄ±, size kodu gÃ¶nderip, telefonunu kapatÄ±p tatile gitti.\n","\n","Maalesef kodu Ã§alÄ±ÅŸmÄ±yor ğŸ˜§. Bu akÅŸam mesai bitmeden mÃ¼ÅŸteriye Ã§alÄ±ÅŸan yazÄ±lÄ±mÄ± gÃ¶ndermeniz gerekiyor ve bu kod, yazÄ±lÄ±mÄ±n dÃ¼zgÃ¼n Ã§alÄ±ÅŸmasÄ± iÃ§in Ã¶nemli. Kodu olmasÄ± gerektiÄŸi gibi Ã§alÄ±ÅŸÄ±r hale getirebilir misiniz?\n","\n","Kodu Ã§alÄ±ÅŸtÄ±rmanÄ±z ve error almadan normal ÅŸekilde sonuÃ§ alabiliyor olmanÄ±z lazÄ±m!\n","\n","Not: input cell'i yani ilk cell dÄ±ÅŸÄ±ndaki cell'leri istediÄŸiniz gibi deÄŸiÅŸtirebilir, yeni cell'ler aÃ§Ä±p, istemediklerinizi silebilirsiniz.\n","\n","(Her bir doÄŸru dÃ¼zeltme +5 puan ğŸ˜€) -- Buradan kaÃ§ dÃ¼zeltme gerektiÄŸini hesaplayabilirsiniz ğŸ˜‰\n","\n","(Her bir yanlÄ±ÅŸ/gereksiz deÄŸiÅŸiklik -1 puan ğŸ˜)\n","\n","Not: YanlÄ±ÅŸ dÃ¼zeltmeden kastÄ±m, hata olmadÄ±ÄŸÄ± halde hatalÄ±ymÄ±ÅŸ gibi yapacaÄŸÄ±nÄ±z gereksiz deÄŸiÅŸiklikler. Yoksa veriler neye benziyor diye ekleyeceÄŸiniz print amaÃ§lÄ± ekler gereksiz sayÄ±lmÄ±yor, istediÄŸiniz kadar ekleyebilirsiniz onlarÄ± ve onlarÄ± eklediÄŸinizi yazmanÄ±za gerek yok aÃ§Ä±klama kÄ±smÄ±nda.\n","\n","Not: ChatGPT ya da Bard bazÄ± hatalarÄ± yakalayamÄ±yor, bazen de gereksiz dÃ¼zeltmeler yapabiliyor. ÅÃ¼phe duyduÄŸunuz durumda derste Ã¶ÄŸrendiklerinize gÃ¼venin! ArkadaÅŸlarÄ±nÄ±za da gÃ¼venmeyin, hata yapacaksanÄ±z kendi hatanÄ±z olsun!"],"metadata":{"id":"JLB1lYsF4j78"}},{"cell_type":"code","source":["# Bu kÄ±sÄ±m zaten sizde vardÄ±. Kodun Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ±\n","# bu random veriler ile deniyorsunuz. \n","# Yani bu cell'de dÃ¼zeltmeniz gereken bir ÅŸey yok!\n","# Ama print statement'larÄ± ekleyerek input neye benziyor diye bakmanÄ±z,\n","# eklemeler yapmanÄ±z serbest! Orjinal iÃ§eriÄŸi deÄŸiÅŸtirmeyin yeter!\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import TensorDataset, DataLoader\n","import numpy as np\n","\n","# Create random training and validation data\n","np.random.seed(0)\n","train_data = np.random.rand(160, 5)\n","train_labels = np.random.randint(0, 3, (160,))\n","\n","val_data = np.random.rand(32, 5)\n","val_labels = np.random.randint(0, 3, (32,))\n","\n","# Convert data to PyTorch tensors\n","train_data = torch.Tensor(train_data)\n","train_labels = torch.Tensor(train_labels).long()\n","val_data = torch.Tensor(val_data)\n","val_labels = torch.Tensor(val_labels).long()\n","\n","print(train_data.shape)\n","print(train_labels.shape)\n","print(val_data.shape)\n","print(val_labels.shape)"],"metadata":{"id":"U0L51GSa7gJW","colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"status":"ok","timestamp":1686147179951,"user_tz":-180,"elapsed":235,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}},"outputId":"94995a17-c816-498a-96ba-5eefc4f1aa0d"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([160, 5])\n","torch.Size([160])\n","torch.Size([32, 5])\n","torch.Size([32])\n"]}]},{"cell_type":"code","source":["# Bu ve devamÄ±ndaki cell'lerde stajyeriniz Ã§ok hata yapmÄ±ÅŸ :(\n","# Ondan istenen, yukarÄ±daki cell'de verilen tipteki bir input tarzÄ± iÃ§in\n","# uygun bir iki hidden layer'lÄ± multilayer perceptron oluÅŸturmaktÄ±.\n","# Hidden layer size'larÄ±nÄ±n seÃ§imini ona bÄ±rakmÄ±ÅŸtÄ±nÄ±z (siz de serbestsiniz)\n","# Learning rate'i deÄŸiÅŸtirmek isterseniz serbestsiniz\n","\n","# Neural network modeli\n","class SimpleNet(nn.Module): # Bu class'ta herÅŸey doÄŸru mu?\n","    def __init__(self):     # HayÄ±r, iki hidden layer olmasÄ± gerekirken sadece output layer oluÅŸturulmuÅŸ\n","        super(SimpleNet, self).__init__()\n","        self.inputt = nn.Linear(5,10)\n","        self.hidden1 = nn.Linear(10,10)\n","        self.hidden2 = nn.Linear(10,5)\n","        self.fc = nn.Linear(5, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        x = self.sigmoid(self.inputt(x))\n","        x = self.sigmoid(self.hidden1(x))\n","        x = self.sigmoid(self.hidden2(x))\n","        x = self.sigmoid(self.fc(x))\n","        return x"],"metadata":{"id":"7GfhJ5zmAl__","executionInfo":{"status":"ok","timestamp":1686147660394,"user_tz":-180,"elapsed":231,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0) # Bu seed'i deÄŸiÅŸtirmeyin\n","\n","# bu cell de hata dolu\n","\n","# Create TensorDatasets\n","train_dataset = TensorDataset(train_data, train_labels)\n","val_dataset = TensorDataset(val_data, val_labels)\n","\n","# Define batch size\n","batch_size = 16\n","\n","# Create DataLoaders for training and validation\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# Model'i oluÅŸturuyorum baÅŸlangÄ±Ã§ iÃ§in\n","model = SimpleNet()\n","\n","criterion = nn.BCELoss()\n","# criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adagrad(model.parameters(), lr=0.01)\n"],"metadata":{"id":"Vo2LOItcAuLp","executionInfo":{"status":"ok","timestamp":1686148584986,"user_tz":-180,"elapsed":231,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["torch.manual_seed(0) # Bu seed'i deÄŸiÅŸtirmeyin\n","\n","# Training ve validation burada.\n","# Buralarda da Ã§ok hata var :(\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","\n","    # Training loop\n","    for batch_data, batch_labels in (train_loader):\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = model(batch_data)\n","        loss = criterion(outputs.squeeze(), batch_labels)\n","\n","        # Backward pass\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Accumulate the loss\n","        running_loss += loss.item()\n","\n","    # Compute average training loss for the epoch\n","    train_loss = running_loss / len(train_loader)\n","\n","    val_loss = 0.0\n","\n","    # Iterate over the validation batches\n","    for batch_data, batch_labels in val_loader:\n","        val_outputs = model(batch_data)\n","        batch_loss = criterion(val_outputs.squeeze(), batch_labels)\n","        val_loss += batch_loss.item()\n","\n","    # Compute average validation loss for the epoch\n","    val_loss /= len(val_loader)\n","\n","    # Print loss and validation loss\n","    print(f\"Train_loss: {train_loss}, Val_loss: {val_loss}\")\n","\n","print(\"Training bitti\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":487},"id":"IR2dqMf65bRo","outputId":"eb893877-417c-4349-f426-b765770fb137","executionInfo":{"status":"error","timestamp":1686148887340,"user_tz":-180,"elapsed":249,"user":{"displayName":"Demircan Ã–zdemir","userId":"10510703038903560942"}}},"execution_count":61,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-eb5302aaccdd>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3096\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3098\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Found dtype Long but expected Float"]}]},{"cell_type":"markdown","source":["Hangi hatalarÄ± buldunuz/dÃ¼zelttiniz/neleri deÄŸiÅŸtirdiniz? KÄ±saca madde madde yazÄ±n ki stajyer telefonunu aÃ§tÄ±ÄŸÄ±nda ona liste halinde gÃ¶nderin hatalarÄ±nÄ±, dÃ¼zgÃ¼n kod yazmayÄ± Ã¶ÄŸrensin.\n","\n","\n","\n","*   SimpleNet modelinde sadece output layer'Ä± vardÄ± input layer ve diÄŸer iki hidden layer eksikti. AyrÄ±ca \"foward\" fonksiyonu iÃ§erisinde de yalnÄ±zca output layerda bir aktivasyon fonksiyonu uygulanmÄ±ÅŸtÄ±.\n","*   train_loader ve val_loader'da batch_size verilmesi unutulmuÅŸtu. ve optimizer Ã§aÄŸÄ±rÄ±lÄ±rken syntax hatasÄ± yapÄ±lmÄ±ÅŸtÄ±.\n","\n","*   Print kÄ±smÄ±nda train_loss ve val_loss deÄŸerleri yazdÄ±rÄ±lmamÄ±ÅŸ.\n","\n"],"metadata":{"id":"VKTvlUrvBUnT"}}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"1Lv0_QLcQrXibu8OJv6fUL5uwRJ6xAO7P","timestamp":1686139482968}]},"accelerator":"TPU"},"nbformat":4,"nbformat_minor":0}